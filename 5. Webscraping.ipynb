{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 \n",
    "### Webscraping "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "#### HTML page structure\n",
    "\n",
    "**Hypertext Markup Language (HTML)** is the standard markup language for documents designed to be displayed in a web browser. HTML describes the structure of a web page and it can be used with **Cascading Style Sheets (CSS)** and a scripting language such as **JavaScript** to create interactive websites. HTML consists of a series of elements that \"tell\" to the browser how to display the content. Lastly, elements are represented by **tags**.\n",
    "\n",
    "Here are some tags:\n",
    "* `<!DOCTYPE html>` declaration defines this document to be HTML5.  \n",
    "* `<html>` element is the root element of an HTML page.  \n",
    "* `<div>` tag defines a division or a section in an HTML document. It's usually a container for other elements.\n",
    "* `<head>` element contains meta information about the document.  \n",
    "* `<title>` element specifies a title for the document.  \n",
    "* `<body>` element contains the visible page content.  \n",
    "* `<h1>` element defines a large heading.  \n",
    "* `<p>` element defines a paragraph.  \n",
    "* `<a>` element defines a hyperlink.\n",
    "\n",
    "HTML tags normally come in pairs like `<p>` and `</p>`. The first tag in a pair is the opening tag, the second tag is the closing tag. The end tag is written like the start tag, but with a slash inserted before the tag name.\n",
    "\n",
    "<img src=\"https://github.com/nestauk/im-tutorials/blob/3-ysi-tutorial/figures/Web-Scraping/tags.png?raw=1\" width=\"512\">\n",
    "\n",
    "HTML has a tree-like ðŸŒ³ ðŸŒ² structure thanks to the **Document Object Model (DOM)**, a cross-platform and language-independent interface. Here's how a very simple HTML tree looks like.\n",
    "\n",
    "<img src=\"https://github.com/nestauk/im-tutorials/blob/3-ysi-tutorial/figures/Web-Scraping/dom_tree.gif?raw=1\">\n",
    "\n",
    "### Creating a simple HTML page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\" dir=\"ltr\">\n",
    "<head>\n",
    "  <title>Intro to HTML</title>\n",
    "</head>\n",
    "\n",
    "<body>\n",
    "  <h1>Heading h1</h1>\n",
    "  <h2>Heading h2</h2>\n",
    "  <h3>Heading h3</h3>\n",
    "  <h4>Heading h4</h4>\n",
    "\n",
    "  <p>\n",
    "    That's a text paragraph. You can also <b>bold</b>, <mark>mark</mark>, <ins>underline</ins>, <del>strikethrough</del> and <i>emphasize</i> words.\n",
    "    You can also add links - here's one to <a href=\"https://en.wikipedia.org/wiki/Main_Page\">Wikipedia</a>.\n",
    "  </p>\n",
    "\n",
    "  <p>\n",
    "    This <br> is a paragraph <br> with <br> line breaks\n",
    "  </p>\n",
    "\n",
    "  <p style=\"color:red\">\n",
    "    Add colour to your paragraphs.\n",
    "  </p>\n",
    "\n",
    "  <p>Unordered list:</p>\n",
    "  <ul>\n",
    "    <li>Python</li>\n",
    "    <li>R</li>\n",
    "    <li>Julia</li>\n",
    "  </ul>\n",
    "\n",
    "  <p>Ordered list:</p>\n",
    "  <ol>\n",
    "    <li>Data collection</li>\n",
    "    <li>Exploratory data analysis</li>\n",
    "    <li>Data analysis</li>\n",
    "    <li>Policy recommendations</li>\n",
    "  </ol>\n",
    "  <hr>\n",
    "\n",
    "  <!-- This is a comment -->\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f07075e99eb14b03be308e3156fc8a8a02d87cdd"
   },
   "source": [
    "In this simple kernal, we will use `BeautifulSoup` to scrape the International Movies Database (IMDB) at [imdb.com](https://imdb.com) for top films released in year 2020 with the highest US box office. \n",
    "\n",
    "I am organizing the final results as a dataframe with below elements:\n",
    "\n",
    "* `name` - title of the movie, \n",
    "* `year` - release year of the movie, \n",
    "* `imdb` - IMDB score of the movie, \n",
    "* `m_score` - meta score of the movie, \n",
    "* `vote` - number of votes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9b1eef50248c5263a75621ab52a9f1af0b996b83"
   },
   "source": [
    "First, we import the requried packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dda98d2e9ae4faf439deaa1592f4844f8baac1cd"
   },
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "import time\n",
    "import random as ran\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c924018be5930d4b8c21cc0bb957ad5025375879"
   },
   "source": [
    "Now I search for the for [top 1000 films released in year of 2020 at imdb.com](https://www.imdb.com/search/title?release_date=2020&sort=boxoffice_gross_us,desc&start=1) and scrape results from the first page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "21f25f231667b0863479574771aa5961f1a40da8"
   },
   "outputs": [],
   "source": [
    "url = 'https://www.imdb.com/search/title/?release_date=2020&sort=boxoffice_gross_us,desc&start=1'\n",
    "\n",
    "source = requests.get(url).text\n",
    "soup = bs4.BeautifulSoup(source,'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4577e2bcc6733252c17b5b44abb4ef53351efdfe"
   },
   "source": [
    "Since above code extracts all data on the first page, below code is run only to extract movie information on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1275751323d1baa89fa8290b6cff594a14eb8934"
   },
   "outputs": [],
   "source": [
    "movie_blocks = soup.findAll('div',{'class':'lister-item-content'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5bb2c969199db0f64dda78e5607aed7395f58c2b"
   },
   "source": [
    "Before extracting information across all movies, we first examine one of the extracted block to identify the elements that we need to scrape.\n",
    "\n",
    "Below we extract the elements from the first movie block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1f377c7e4081459f56d49eff4d929ed820f2575a"
   },
   "outputs": [],
   "source": [
    "mname = movie_blocks[0].find('a').get_text() # Name of the movie\n",
    "\n",
    "m_reyear = int(movie_blocks[0].find('span',{'class': 'lister-item-year'}).contents[0][1:-1]) # Release year\n",
    "\n",
    "m_rating = float(movie_blocks[0].find('div',{'class':'inline-block ratings-imdb-rating'}).get('data-value')) #rating\n",
    "\n",
    "m_mscore = float(movie_blocks[0].find('span',{'class':'metascore mixed'}).contents[0].strip()) #meta score\n",
    "\n",
    "m_votes = int(movie_blocks[0].find('span',{'name':'nv'}).get('data-value')) # votes\n",
    "\n",
    "print(\"Movie Name: \" + mname,\n",
    "      \"\\nRelease Year: \" + str(m_reyear),\n",
    "      \"\\nIMDb Rating: \" + str(m_rating),\n",
    "      \"\\nMeta score: \" + str(m_mscore),\n",
    "      \"\\nVotes: \" + '{:,}'.format(m_votes)\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c70f56d7ccd87d574e0be02656e44b1ab6435b4c"
   },
   "source": [
    "Once you examine the resulting pages of the imbd search that we initially did , it's obvious that by editing the html link it is possible to view all search results. We will use this feature during the scrape to iterate through all pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b36f51a41f37b2e68a4149a42eaa64b9b8ae097c"
   },
   "source": [
    "Now since scraping the data is an iterative process, lets create separate functions for each purpose.\n",
    "\n",
    "First lets define a function which will extract the targeted elements from a 'movie block list' (discussed above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "548ab4039c3a6e419ddbdd2bc1c93c577800c5d6"
   },
   "outputs": [],
   "source": [
    "def scrape_mblock(movie_block):\n",
    "    \n",
    "    movieb_data ={}\n",
    "  \n",
    "    try:\n",
    "        movieb_data['name'] = movie_block.find('a').get_text() # Name of the movie\n",
    "    except:\n",
    "        movieb_data['name'] = None\n",
    "\n",
    "    try:    \n",
    "        movieb_data['year'] = str(movie_block.find('span',{'class': 'lister-item-year'}).contents[0][1:-1]) # Release year\n",
    "    except:\n",
    "        movieb_data['year'] = None\n",
    "\n",
    "    try:\n",
    "        movieb_data['rating'] = float(movie_block.find('div',{'class':'inline-block ratings-imdb-rating'}).get('data-value')) #rating\n",
    "    except:\n",
    "        movieb_data['rating'] = None\n",
    "\n",
    "    try:\n",
    "        movieb_data['m_score'] = float(movie_block.find('span',{'class':'metascore mixed'}).contents[0].strip()) #meta score\n",
    "    except:\n",
    "        movieb_data['m_score'] = None\n",
    "\n",
    "    try:\n",
    "        movieb_data['votes'] = int(movie_block.find('span',{'name':'nv'}).get('data-value')) # votes\n",
    "    except:\n",
    "        movieb_data['votes'] = None\n",
    "\n",
    "    return movieb_data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f28bd9e7abe441563183dfd4707d1a1fb7163fc5"
   },
   "source": [
    "Then create the below function to scrape all movie blocks within a single search result page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d65617221159bccad080a325a574aa901c94a451"
   },
   "outputs": [],
   "source": [
    "def scrape_m_page(movie_blocks):\n",
    "    \n",
    "    page_movie_data = []\n",
    "    num_blocks = len(movie_blocks)\n",
    "    \n",
    "    for block in range(num_blocks):\n",
    "        page_movie_data.append(scrape_mblock(movie_blocks[block]))\n",
    "    \n",
    "    return page_movie_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b96947baac69667a01b4a851932d3c227003c8cc"
   },
   "source": [
    "Now we built functions to extract all movie data from a single page.\n",
    "\n",
    "Next function will be created to iterate the above made function through all pages of the search result untill we scrape data for the targeted number of movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c5656aa65b04b82a57a1caf8ff68e27a88ef5e21"
   },
   "outputs": [],
   "source": [
    "def scrape_this(link,t_count):\n",
    "    \n",
    "    #from IPython.core.debugger import set_trace\n",
    "\n",
    "    base_url = link\n",
    "    target = t_count\n",
    "    \n",
    "    current_mcount_start = 0\n",
    "    current_mcount_end = 0\n",
    "    remaining_mcount = target - current_mcount_end \n",
    "    \n",
    "    new_page_number = 1\n",
    "    \n",
    "    movie_data = []\n",
    "    \n",
    "    \n",
    "    while remaining_mcount > 0:\n",
    "\n",
    "        url = base_url + str(new_page_number)\n",
    "        \n",
    "        #set_trace()\n",
    "        \n",
    "        source = requests.get(url).text\n",
    "        soup = bs4.BeautifulSoup(source,'html.parser')\n",
    "        \n",
    "        movie_blocks = soup.findAll('div',{'class':'lister-item-content'})\n",
    "        \n",
    "        movie_data.extend(scrape_m_page(movie_blocks))   \n",
    "        \n",
    "        current_mcount_start = int(soup.find(\"div\", {\"class\":\"nav\"}).find(\"div\", {\"class\": \"desc\"}).contents[1].get_text().split(\"-\")[0])\n",
    "\n",
    "        current_mcount_end = int(soup.find(\"div\", {\"class\":\"nav\"}).find(\"div\", {\"class\": \"desc\"}).contents[1].get_text().split(\"-\")[1].split(\" \")[0])\n",
    "\n",
    "        remaining_mcount = target - current_mcount_end\n",
    "        \n",
    "        print('\\r' + \"currently scraping movies from: \" + str(current_mcount_start) + \" - \"+str(current_mcount_end), \"| remaining count: \" + str(remaining_mcount), flush=True, end =\"\")\n",
    "        \n",
    "        new_page_number = current_mcount_end + 1\n",
    "        \n",
    "        time.sleep(ran.randint(0, 10))\n",
    "    \n",
    "    return movie_data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "36432981ed2585a52a2e97314d403c6a0f6529fb"
   },
   "source": [
    "Finally, put together all functions created above to scrape the top 150 movies on the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "efca380155228307997551c37fe3f10c13b7e008"
   },
   "outputs": [],
   "source": [
    "base_scraping_link = \"https://www.imdb.com/search/title?release_date=2020-01-01,2020-12-31&sort=boxoffice_gross_us,desc&start=\"\n",
    "\n",
    "top_movies = 150 #input(\"How many movies do you want to scrape?\")\n",
    "films = []\n",
    "\n",
    "films = scrape_this(base_scraping_link,int(top_movies))\n",
    "\n",
    "print('\\r'+\"List of top \" + str(top_movies) +\" movies:\" + \"\\n\", end=\"\\n\")\n",
    "pd.DataFrame(films)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Advanced web scraping tools\n",
    "\n",
    "**[Scrapy](https://scrapy.org)** is a Python framework for large scale web scraping. It gives you all the tools you need to efficiently extract data from websites, process them as you want, and store them in your preferred structure and format.\n",
    "\n",
    "**[ARGUS](https://github.com/datawizard1337/ARGUS)** is an easy-to-use web mining tool that's built on Scrapy. It is able to crawl a broad range of different websites.\n",
    "\n",
    "**[Selenium](https://selenium-python.readthedocs.io/index.html)** is an umbrella project encapsulating a variety of tools and libraries enabling web browser automation. Selenium specifically provides infrastructure for the W3C WebDriver specification â€” a platform and language-neutral coding interface compatible with all major web browsers. We can use it to imitate a user's behaviour and interact with Javascript elements (buttons, sliders etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
